# BanVic ETL Pipeline

Este projeto implementa um pipeline de **ETL (Extract, Transform, Load)** utilizando **Apache Airflow** e **PostgreSQL**.  
O objetivo Ã© centralizar dados de diferentes fontes (ERP, CRM, Marketing) em um **Data Warehouse** para possibilitar anÃ¡lises e integraÃ§Ã£o com ferramentas de BI (Metabase, PowerBI, Looker, etc.).

---

## ğŸš€ VisÃ£o Geral do Pipeline

Fluxo de dados:

1. **ExtraÃ§Ã£o**  
   - Tabelas do banco de origem (`source_db`, inicializado a partir de `banvic.sql`)  
   - Arquivo CSV de transaÃ§Ãµes (`transacoes.csv`)  

2. **Armazenamento TemporÃ¡rio (Data Lake Local)**  
   - Os dados extraÃ­dos sÃ£o salvos em CSV no diretÃ³rio `data/`  
   - Estrutura de diretÃ³rios:  
     ```
     data/<ano>-<mes>-<dia>/
        â”œâ”€â”€ sql/
        â”‚    â”œâ”€â”€ clientes.csv
        â”‚    â”œâ”€â”€ contas.csv
        â”‚    â”œâ”€â”€ propostas_credito.csv
        â”‚    â””â”€â”€ agencias.csv
        â””â”€â”€ csv/
             â””â”€â”€ transacoes.csv
     ```

3. **Carga no Data Warehouse (DW)**  
   - Os CSVs sÃ£o carregados em um banco PostgreSQL separado (`dw_postgres`)  
   - As tabelas sÃ£o recriadas a cada execuÃ§Ã£o (idempotÃªncia)  

4. **VerificaÃ§Ã£o**  
   - O pipeline executa queries de contagem (`SELECT COUNT(*)`) no DW para garantir que os dados foram carregados corretamente.  

---

## ğŸ› ï¸ Tecnologias Utilizadas

- [Apache Airflow 2.7.2](https://airflow.apache.org/) â†’ OrquestraÃ§Ã£o das tarefas  
- [PostgreSQL 16](https://www.postgresql.org/) â†’ Banco de origem e Data Warehouse  
- [Docker Compose](https://docs.docker.com/compose/) â†’ Gerenciamento dos serviÃ§os  

---
## ğŸ“‚ Estrutura do Projeto
ETL-pipeline-de-dados/
â”œâ”€â”€ dags/
â”‚ â””â”€â”€ banvic_dag.py # DAG do Airflow (pipeline principal)
â”œâ”€â”€ source_db/
â”‚ â””â”€â”€ banvic.sql # Dump SQL do banco de origem
â”œâ”€â”€ source_data/
â”‚ â””â”€â”€ transacoes.csv # Arquivo CSV de transaÃ§Ãµes
â”œâ”€â”€ data/ # Data Lake (gerado automaticamente)
â”œâ”€â”€ dbdata/ # Volume do banco de origem (Postgres)
â”œâ”€â”€ dwdata/ # Volume do Data Warehouse
â”œâ”€â”€ airflow_db/ # Volume do metadatabase do Airflow
â””â”€â”€ docker-compose.yml # ConfiguraÃ§Ã£o dos serviÃ§os






<img width="740" height="332" alt="image" src="https://github.com/user-attachments/assets/b7d67ea4-9ca4-4cff-83ca-d56176ef0f37" />



